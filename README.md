# üêç Crawler com Scrapy

![GitHub repo size](https://img.shields.io/github/repo-size/Drack112/Scrapy-Books?style=for-the-badge)
![GitHub language count](https://img.shields.io/github/languages/count/Drack112/Scrapy-Books?style=for-the-badge)
![GitHub forks](https://img.shields.io/github/forks/Drack112/Scrapy-Books?style=for-the-badge)
![Bitbucket open issues](https://img.shields.io/bitbucket/issues/Drack112/Scrapy-Books?style=for-the-badge)
![Bitbucket open pull requests](https://img.shields.io/bitbucket/pr-raw/Drack112/Scrapy-Books?style=for-the-badge)

### ‚≠ê Fun√ß√µes e adeptos

- [x] Testes com o pacote Scrapy do python, com fun√ß√µes de crawler e automatiza√ß√µes

## üöÄ

```bash
$ pip install -r requirements
```

## ‚òï Rodando

Preencha o arquivo `settings.py` com as informa√ß√µes cobradas.

Pegue as credenciais do app na plataforma [ScrapeOps](https://scrapeops.io)

Agora rode a aplica√ß√£o com:

```bash
$ docker-compose up
```

E por fim, rode o aplicativo:

```bash
$ scrapy crawl bookspider
```
